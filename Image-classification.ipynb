{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Histology images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature extraction through pretrained model + hand picked features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIKET RAJ\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import os\n",
    "import re\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Input\n",
    "from keras.preprocessing import image\n",
    "K.set_image_data_format('channels_last')\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to folder containing four subfolders\n",
    "\n",
    "root_dir = 'C:\\\\Users\\\\ANIKET RAJ\\\\Desktop\\\\keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test set\n",
    "\n",
    "def preprocess_for_training(X,y):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3, shuffle=True,random_state=42)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_reduction(data):\n",
    "    return data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_feature_dimension(data, n_components,mode=None):\n",
    "    data = preprocess_for_reduction(data)\n",
    "    if mode in ['svd_rbf','kmeans',]:\n",
    "        reducer = PCA(n_components=n_components, whiten=True)\n",
    "        reduced = reducer.fit_transform()\n",
    "        return reduced\n",
    "    else:\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        reducer.fit(data)\n",
    "        reduced = reducer.transform(data)\n",
    "        return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation of feature vectors from different methods\n",
    "\n",
    "def add_features(sample1):\n",
    "    X_complete = np.hstack(sample1)\n",
    "    return X_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Feature extraction by VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_vgg16 = 224\n",
    "width_vgg16 = int(height_vgg16*0.75)\n",
    "target_size_vgg16 = (width_vgg16,height_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 168, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 168, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 168, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 84, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 84, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 84, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 42, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 42, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 42, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 21, 256)       0         \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_name_vgg16 = 'block3_pool'\n",
    "model_input_vgg16 = Input((height_vgg16, width_vgg16, 3))\n",
    "#base_model = VGG19(include_top = False,weights='imagenet',input_tensor = model_input, input_shape=target_size)\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor = model_input_vgg16, input_shape=(height_vgg16, width_vgg16, 3))\n",
    "model_vgg16 = Model(inputs=model_input_vgg16, outputs=base_model_vgg16.get_layer(layer_name_vgg16).output)\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract_from_VGG16(image_path ,target_size=target_size_vgg16):\n",
    "                    Model = model_vgg16\n",
    "                    \n",
    "                    img = cv.imread(image_path)\n",
    "                    img = cv.resize(img, target_size)\n",
    "                    img = img/255.0\n",
    "                    #img = image.img_to_array(img)\n",
    "                    #img = img/255.0\n",
    "                    x = np.expand_dims(img, axis=0)\n",
    "                    \n",
    "                    #x = preprocess_input(x)\n",
    "\n",
    "                    features = Model.predict(x)\n",
    "                    \n",
    "                    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_mat_VGG16(root_dir, shape):\n",
    "    img_re = re.compile(r'.+\\.(tif)$', re.IGNORECASE)\n",
    "    feature_mat = np.zeros((shape[0],shape[1]))\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for k,name in enumerate(sorted(dirs)):\n",
    "            sub_path = os.path.join(root,name)\n",
    "            for i,files in enumerate(os.listdir(sub_path)):\n",
    "                if img_re.match(files):\n",
    "                    image_path = os.path.join(sub_path,files)\n",
    "                    features = feature_extract_from_VGG16(image_path=image_path)\n",
    "                    features = features.reshape(-1)\n",
    "                    feature_mat[:,i] = features\n",
    "                    labels.append(name)\n",
    "    return feature_mat, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_vgg16 = 400\n",
    "n_features_vgg16 = 150528\n",
    "nb_test_class_vgg16 = 4\n",
    "shape_vgg16 = (n_features_vgg16, nb_train_vgg16)\n",
    "\n",
    "features_vgg16, labels_vgg16 = create_feature_mat_VGG16(root_dir=root_dir,shape=shape_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing pickle file with features\n",
    "fileObject = open('VGG16_conv4_layer_features','wb')\n",
    "pickle.dump(features, fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'Benign',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'InSitu',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Invasive',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2095.10988883],\n",
       "       [2274.67814144],\n",
       "       [1918.25053715],\n",
       "       [2390.05570884],\n",
       "       [2531.76129728],\n",
       "       [2592.78863574],\n",
       "       [2466.18334495],\n",
       "       [2226.2214887 ],\n",
       "       [2279.59289852],\n",
       "       [2257.84306193],\n",
       "       [2208.5786437 ],\n",
       "       [2227.39480639],\n",
       "       [2183.71101853],\n",
       "       [2204.58317812],\n",
       "       [2402.52628059],\n",
       "       [2617.51557174],\n",
       "       [2575.28459845],\n",
       "       [1917.74013927],\n",
       "       [2074.752119  ],\n",
       "       [2374.34361675],\n",
       "       [2304.10709644],\n",
       "       [1998.41722567],\n",
       "       [2287.77430002],\n",
       "       [2336.65559174],\n",
       "       [2349.03635256],\n",
       "       [1920.37888864],\n",
       "       [2221.50870709],\n",
       "       [2255.70026358],\n",
       "       [2484.37676192],\n",
       "       [2217.74757377],\n",
       "       [2330.40963595],\n",
       "       [2148.2020235 ],\n",
       "       [2007.50253068],\n",
       "       [2126.93348637],\n",
       "       [1983.71892425],\n",
       "       [2184.78070638],\n",
       "       [2144.64312796],\n",
       "       [2038.42038566],\n",
       "       [2351.88265732],\n",
       "       [2214.1021062 ],\n",
       "       [2220.62769397],\n",
       "       [2363.57250981],\n",
       "       [2102.16336239],\n",
       "       [2357.11510497],\n",
       "       [2232.13814408],\n",
       "       [2185.97725595],\n",
       "       [2213.44702444],\n",
       "       [2141.29519092],\n",
       "       [2659.95757675],\n",
       "       [2102.34568197],\n",
       "       [2198.66660627],\n",
       "       [2189.20596125],\n",
       "       [2171.46921829],\n",
       "       [2127.28635864],\n",
       "       [2130.94801204],\n",
       "       [2416.8334455 ],\n",
       "       [2045.46005792],\n",
       "       [2097.80428871],\n",
       "       [2447.62533731],\n",
       "       [2236.45037967],\n",
       "       [2377.01276302],\n",
       "       [2235.09869549],\n",
       "       [2307.25640813],\n",
       "       [2193.55714098],\n",
       "       [2079.43721111],\n",
       "       [2106.17231196],\n",
       "       [2178.52346856],\n",
       "       [2159.10144676],\n",
       "       [2248.78142999],\n",
       "       [2448.86401726],\n",
       "       [2402.94791885],\n",
       "       [2240.32975036],\n",
       "       [2355.86184254],\n",
       "       [2284.54379104],\n",
       "       [2106.97254328],\n",
       "       [2199.37734712],\n",
       "       [2048.91414972],\n",
       "       [2139.75396765],\n",
       "       [2277.94139768],\n",
       "       [2223.07121292],\n",
       "       [2428.32299719],\n",
       "       [2227.23024145],\n",
       "       [2464.63994073],\n",
       "       [2238.31653266],\n",
       "       [2130.60695611],\n",
       "       [2277.53044839],\n",
       "       [2415.19365917],\n",
       "       [2496.41861833],\n",
       "       [2503.32902803],\n",
       "       [2287.14072957],\n",
       "       [2327.55875585],\n",
       "       [2259.61053224],\n",
       "       [2246.21068247],\n",
       "       [2530.09232639],\n",
       "       [2379.93369632],\n",
       "       [2401.06024652],\n",
       "       [2483.66503243],\n",
       "       [2515.59676287],\n",
       "       [2551.21650869],\n",
       "       [2358.47263963],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561],\n",
       "       [-755.00422561]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vgg16 = reduce_feature_dimension(features_vgg16, n_components=100)\n",
    "X_vgg16.shape\n",
    "X_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train , X_test , y_test = preprocess_for_training(X_vgg16,labels_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy =  0.5166666666666667\n",
      "training set accuracy =  0.4928571428571429\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print('test set accuracy = ',svm_model.score(X_test, y_test))\n",
    "print('training set accuracy = ',svm_model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reading hand picked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('C:\\\\Users\\\\ANIKET RAJ\\\\Desktop\\\\keras\\\\extraf.csv')\n",
    "\n",
    "x.sort_values(by='name',inplace=True)\n",
    "\n",
    "x['label'] = x['label'].map({2:'Benign',1:'Normal',3:'InSitu',4:'Invasive'})\n",
    "col = x.columns\n",
    "xtra_feature = x.iloc[:,1:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combining features and calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------  combining vgg16 and our own feature  --------')\n",
    "\n",
    "X_complete = add_features([X_vgg16,xtra_feature])\n",
    "print('feature vector shape --> ',X_complete.shape)\n",
    "X_train,y_train , X_test , y_test = preprocess_for_training(X_complete,labels_vgg16)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print('test set accuracy = ',svm_model.score(X_test, y_test))\n",
    "print('train set accuracy = ',svm_model.score(X_train, y_train))\n",
    "\n",
    "print('______________________________________________________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
